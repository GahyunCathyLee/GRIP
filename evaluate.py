import argparse
import os
import yaml
import time
from highD.preprocess import get_num_channels
import numpy as np
import torch
import torch.nn as nn
from tqdm import tqdm
from pathlib import Path

from model import Model
from feeder import HighDFeeder as Feeder

EXTRA_FEATURE_MAP = {
    'baseline': [0, 1],
    'baseline_v': [2, 3],
    'exp1': [0, 1, 8],
    'exp2': [0, 1, 6, 7],
    'exp3': [6, 7],
    'exp4': [4, 5, 6, 7, 8],
    'exp5': [0, 1, 2, 3, 4, 5, 8],
    'exp6': [0, 1, 2, 3, 4, 5, 6, 7, 8],
}

def get_num_channels(feature_mode):
    return 2 + len(EXTRA_FEATURE_MAP[feature_mode]) + 1

def get_args():
    parser = argparse.ArgumentParser(description='GRIP++ Evaluation')
    parser.add_argument('--config', type=str, default='configs/baseline.yaml', help='path to config file')
    parser.add_argument('--ckpt', type=str, required=True, help='path to model checkpoint (.pt)')
    parser.add_argument('--measure_time', action='store_true', help='measure inference time with batch size 1')
    return parser.parse_args()

def calculate_metrics(pred, target):
    """
    pred: (N, T, 2)
    target: (N, T, 2)
    """
    # ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°: (N, T)
    diff = pred - target
    dist = torch.norm(diff, p=2, dim=-1) 

    # 1. ADE (Average Displacement Error)
    ade = torch.mean(dist).item()

    # 2. FDE (Final Displacement Error)
    fde = torch.mean(dist[:, -1]).item()

    # 3. RMSE (Root Mean Square Error)
    # RMSE = sqrt(mean(dist^2))
    rmse = torch.sqrt(torch.mean(dist**2)).item()

    # 4. RMSE @ 1s ~ 5s (Data freqê°€ 5Hzì¸ ê²½ìš°: 5, 10, 15, 20, 25 frames)
    # ì‚¬ìš©ìì˜ ë°ì´í„° ì£¼ê¸°ì— ë§ì¶° ì¸ë±ìŠ¤ë¥¼ ì¡°ì ˆí•˜ì„¸ìš”.
    rmse_steps = {}
    fps = 5 # 5Hz ê°€ì •
    for s in range(1, 6):
        idx = s * fps - 1
        if idx < pred.shape[1]:
            step_rmse = torch.sqrt(torch.mean(dist[:, idx]**2)).item()
            rmse_steps[f'RMSE@{s}s'] = step_rmse

    return ade, fde, rmse, rmse_steps

def evaluate(model, loader, device):
    model.eval()
    all_ade, all_fde, all_rmse = [], [], []
    all_step_rmse = {f'RMSE@{s}s': [] for s in range(1, 6)}

    print(f"ğŸ” í‰ê°€ ì‹œì‘ (Samples: {len(loader.dataset)})")
    
    with torch.no_grad():
        for data, adj, target in tqdm(loader, desc="Eval"):
            data, adj, target = data.to(device).float(), adj.to(device).float(), target.to(device).float()
            
            if data.shape[1] != model.in_channels:
                data = data.permute(0, 3, 2, 1)

            # Inference
            output = model(data, adj, target.shape[1])
            # Ego ì°¨ëŸ‰(0ë²ˆ ë…¸ë“œ)ë§Œ ì¶”ì¶œ: (N, C, T, V) -> (N, T, C)
            ego_pred = output[:, :, :, 0].permute(0, 2, 1)

            # Metrics
            ade, fde, rmse, step_rmse = calculate_metrics(ego_pred, target)
            
            all_ade.append(ade)
            all_fde.append(fde)
            all_rmse.append(rmse)
            for k, v in step_rmse.items():
                all_step_rmse[k].append(v)

    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*50)
    print(f"ğŸ“Š Final Results (m)")
    print(f"  â€¢ ADE  : {np.mean(all_ade):.4f}")
    print(f"  â€¢ FDE  : {np.mean(all_fde):.4f}")
    print(f"  â€¢ RMSE : {np.mean(all_rmse):.4f}")
    print("-" * 50)
    for k, v in all_step_rmse.items():
        print(f"  â€¢ {k:8s} : {np.mean(v):.4f}")
    print("="*50 + "\n")

def measure_inference_time(model, loader, device, iterations=10000):
    model.eval()
    print(f"â±ï¸ Inference Time ì¸¡ì • ì‹œì‘ (Batch Size: 1, Iterations: {iterations})")
    
    # 1. ë‹¨ì¼ ìƒ˜í”Œ ì¤€ë¹„
    data, adj, target = next(iter(loader))
    data, adj = data[0:1].to(device).float(), adj[0:1].to(device).float()
    if data.shape[1] != model.in_channels:
        data = data.permute(0, 3, 2, 1)
    
    pred_len = target.shape[1]
    times = []

    # 2. Warm-up (GPU ì˜ˆì—´) - ë“œë¼ì´ë²„ ë° cuDNN ì´ˆê¸°í™” ì‹œê°„ ì œì™¸
    for _ in range(100):
        with torch.no_grad():
            _ = model(data, adj, pred_len)
    torch.cuda.synchronize()

    # 3. ì‹¤ì œ ì¸¡ì • ë£¨í”„
    print(f"ğŸš€ Measuring...")
    with torch.no_grad():
        for _ in range(iterations):
            start_time = time.time()
            
            _ = model(data, adj, pred_len)
            
            torch.cuda.synchronize()  # GPU ì—°ì‚°ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
            end_time = time.time()
            
            times.append((end_time - start_time) * 1000)  # ms ë‹¨ìœ„ë¡œ ì €ì¥

    # 4. í†µê³„ ê³„ì‚° (numpy í™œìš©)
    avg_time = np.mean(times)
    std_time = np.std(times)
    min_time = np.min(times)
    max_time = np.max(times)

    # 5. ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*50)
    print(f"ğŸ“Š Inference Time Statistics (ms)")
    print(f"  â€¢ Avg Latency : {avg_time:.4f} ms")
    print(f"  â€¢ Std Dev     : {std_time:.4f} ms")
    print(f"  â€¢ Min Latency : {min_time:.4f} ms")
    print(f"  â€¢ Max Latency : {max_time:.4f} ms")
    print("-" * 50)
    print(f"  â€¢ FPS (Avg)   : {1000/avg_time:.2f} frames/s")
    print("="*50 + "\n")

def main():
    args = get_args()
    with open(args.config, 'r') as f:
        cfg = yaml.safe_load(f)

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # 1. Feature Modeì— ë”°ë¥¸ ìë™ ì…ë ¥ ì±„ë„ ì„¤ì •
    feature_mode = cfg['exp']['feature_mode']
    in_channels = get_num_channels(feature_mode)
    
    # 2. ëª¨ë¸ ë¡œë“œ
    model = Model(in_channels=in_channels, 
                  graph_args={'max_hop': cfg['model']['max_hop'], 'num_node': cfg['model']['num_node']}, 
                  edge_importance_weighting=cfg['model']['edge_importance_weighting']).to(device)

    # ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°
    checkpoint = torch.load(args.ckpt, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    print(f"âœ… Checkpoint Loaded: {args.ckpt}")

    # 2. ë°ì´í„° ë¡œë” ì¤€ë¹„ (Test/Val ë°ì´í„°)
    test_path = Path(cfg['data']['base_dir']) / cfg['exp']['feature_mode'] / "test.h5"
    if not test_path.exists():
        test_path = Path(cfg['data']['base_dir']) / cfg['exp']['feature_mode'] / "val.h5"
    
    batch_size = cfg['data'].get('batch_size_val', cfg['data'].get('batch_size', 64))
    
    test_loader = torch.utils.data.DataLoader(
        Feeder(str(test_path)),
        batch_size=batch_size, shuffle=False, num_workers=4
    )

    # 3. ëª¨ë“œë³„ ì‹¤í–‰
    if args.measure_time:
        measure_inference_time(model, test_loader, device)
    else:
        evaluate(model, test_loader, device)

if __name__ == '__main__':
    main()